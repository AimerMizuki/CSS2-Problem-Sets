{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Liu_Siyuan_Problem_set_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW149B5pVJXX"
      },
      "source": [
        "Part 1: import requires libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUmYtOGzussv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "\n",
        "data = sns.load_dataset('geyser')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvzPPQ18NDr0"
      },
      "source": [
        "Part 2: Creat function \"machines_learning\" to perform kfold method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZBbI4KOIr-r"
      },
      "source": [
        "def machine_learning(x, y, folds):\n",
        "  #empty array for training and testing score\n",
        "  training_score = []\n",
        "  testing_score = []\n",
        "\n",
        "  #use linear regression model\n",
        "  model = LinearRegression(fit_intercept=True)\n",
        "\n",
        "  #loops = how many folds\n",
        "  for i in range(1,folds+1):\n",
        "    #how many rows are index at once. caluclated by total row number/number of folds. \n",
        "    index = int(round(len(data)/folds,0))\n",
        "\n",
        "    #if it's the last testing fold, we don't have to index it twice.\n",
        "    if i == folds:\n",
        "      testing = data[(i-1)*index : ]\n",
        "      training = data[~data.isin(testing)].dropna()\n",
        "   \n",
        "    else:\n",
        "      #testing equal data index from \"fold number -1 * index number\" to \"fold number * index number\". \n",
        "      #if i = 0 and folds = 10, data will be index from [0:27]\n",
        "      testing = data[(i-1)*index :(i)*index]\n",
        "      #training data = data -testingdata\n",
        "      training = data[~data.isin(testing)].dropna()\n",
        "\n",
        "    \n",
        "    #Xtrain and Ytrain recieve training data with column name \"x\" or \"y\" to array. For x, reshape it to 2 columns.\n",
        "    Xtrain = np.array(training[x]).reshape((len(training),1))\n",
        "    Ytrain = np.array(training[y])\n",
        "    #Xtrain and Ytrain recieve testing data with column name \"x\" or \"y\" to array. For x, reshape it to 2 columns.\n",
        "    Xtest = np.array(testing[x]).reshape((len(testing),1))\n",
        "    Ytest = np.array(testing[y])\n",
        "\n",
        "    #fit model\n",
        "    model.fit(Xtrain,Ytrain)\n",
        "    #Append training and testing score for each loop into the stored array for training and testing\n",
        "    training_score.append(model.score(Xtrain,Ytrain))\n",
        "    testing_score.append(model.score(Xtest,Ytest))\n",
        "\n",
        "  #print fold number\n",
        "  print(\"When folds = \" ,folds )\n",
        "  #print result with mean&sd of training and testing score\n",
        "  print('Training R^2 : mean = ',np.mean(training_score), \"sd = \" ,np.std(training_score))\n",
        "  print('Testing R^2 : mean = ',np.mean(testing_score), \"sd = \" ,np.std(testing_score))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1q_2-mcXofq"
      },
      "source": [
        "Part 3: Show off the function! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqZnq6tXxgs",
        "outputId": "b59fd57e-c047-4c2f-adef-e2d0b4b9df81"
      },
      "source": [
        "machine_learning('waiting', 'duration', 10)\n",
        "machine_learning('waiting', 'duration', 5)\n",
        "machine_learning('waiting', 'duration', 3)\n",
        "machine_learning('waiting', 'duration', 20)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When folds =  10\n",
            "Training R^2 : mean =  0.8115509101080287 sd =  0.005225253310797004\n",
            "Testing R^2 : mean =  0.8083525567740895 sd =  0.045430607147198473\n",
            "When folds =  5\n",
            "Training R^2 : mean =  0.8116959665550336 sd =  0.004389581073677457\n",
            "Testing R^2 : mean =  0.8088129484571157 sd =  0.017030946649220467\n",
            "When folds =  3\n",
            "Training R^2 : mean =  0.8122519722140896 sd =  0.012034873772231723\n",
            "Testing R^2 : mean =  0.8072394341897106 sd =  0.023847715261583875\n",
            "When folds =  20\n",
            "Training R^2 : mean =  0.8114890251337604 sd =  0.00365582610500259\n",
            "Testing R^2 : mean =  0.801553996960115 sd =  0.0689459423833312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb2tabU_YH12"
      },
      "source": [
        "Part 4: Interpretation\n",
        "\n",
        "  Based on our R^2(0.81155) scores, around 81% of the data fit the regression model we fit for  duration in minutes until the next eruption(\"waiting\")  and the duration of an eruption in minutes (“duration”).In other words, the strength of relationship between \"duration\" and \"waiting\" is around 81%\n",
        "\n",
        "  Repeated kfolds method also revealed that testing scores are almost identical(off by 1%) to the traiing score, which is fantastic. The relationship reveald by the training set is almost equivilent to the relationship of \"waiting\" and \"duration\" if we regenerate another set of data from the same DGP. And also, there are no overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsJwjThpYAcd"
      },
      "source": [
        ""
      ]
    }
  ]
}